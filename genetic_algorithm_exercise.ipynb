{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic algorithms using `numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demonstration, we will code up step-by-step, a simple GA for optimizing a trivial function with constraints. Further exploration in this example would be very useful for your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Do some Ipython black magic\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "rng = np.random.default_rng(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "\n",
    "We need to maximize the function  $ f(\\mathbf{x}) = \\sum_{i=1}^{6} w_i x_i $ for a given set of weights $ w_i $, with the constraints that $ x_i \\; \\in \\; [-4,4] \\; \\forall \\; i$. This means that the domain $\\mathbb{D}$ of the search is $ \\mathbb{D}:= [-4,4]^6$. The optimization problem can be succinctly represented as $\\left(\\mathbb{D}, \\mathbb{R} , \\mathbf{f}, \\geq \\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ease of solving the problem\n",
    "\n",
    "We note that this example is trivial because given a set of weights, we need to pick either $x_i=-4$ or $x_i=4$ as the objective function is linear. That's precisely the point however, as we know the solution to the problem, and we can compare how GA performs (as a search algorithm in itself, and against design parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given\n",
    "The weight vector $\\mathbf{w} = [6,8,-6,3,3,-4]$. For this case then, the optimal solution is $\\mathbf{x}^* = [4, 4, -4, 4, 4, -4]$ which gives a maximum possible objective value $f^* = 120$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WEIGHTS = 6 # Helper variable\n",
    "WEIGHTS = np.array([6,8,-6,3,3,-4], dtype = np.float64) # Optional dtype argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the shape so that we are happy\n",
    "np.shape(WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you want to encode this problem?  We need to keep in mind that variation needs to be done on this representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can define my optimal solution vector now, since I have decided my representation\n",
    "X_STAR = # Fill in based on representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have picked representation, let's start off the problem. We need to pick a population size (i.e. number of parents in the initial generation). Let's pick a nice number, say 10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the population\n",
    "POP_SIZE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember! Each member of this population is a vector with shape `(6,)`. Is there a way to efficiently represent/generate/work with this entire population all at one go?\n",
    "\n",
    "Of course! Put them together as a 2 dimensional array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper variable that generates POP_SIZE x NUM_WEIGHTS population\n",
    "DOFS_IN_POP = (POP_SIZE, N_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The population will have `POP_SIZE` chromosomes where each chromosome has `NUM_WEIGHTS` genes. Let's generate the initial population that our GA algorithm will work on. This population needs to be randomly initialized, say around $0.0$. (Hint : The `numpy.random` module comes to mind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_population = # Fill in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitness assignment\n",
    "In this demo, we assign fitness directly using the objective function (without penalty, we'll deal with constraints later on). However you can best decide what fitness works for your problem (competitive? informal?...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fitness(t_pop):\n",
    "    \"\"\" Calculates fitness given the population using global weights\n",
    "    The fitness function calulates the sum of products between each input and its corresponding weight.\n",
    "    Returns a (POP_SIZE, ) numpy array\n",
    "    \"\"\"       \n",
    "    # Remember : Fitness is a scalar value\n",
    "    fitness = 0.0 # Fill in\n",
    "    \n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "my_fitness = calc_fitness(curr_population)\n",
    "print(my_fitness.shape)\n",
    "print(my_fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection for variation\n",
    "\n",
    "### How do you select parents to spread their genes? \n",
    "One way to do it is to select *best* parents only to mate. This is an example of a **determinstic selection scheme**, wherein we rank them by fitness and consider the best ones.\n",
    "\n",
    "### How many parents to select for mating? \n",
    "This is up to the user. Some people prefer to use heuristics based on the population size for determining the mating pool size. Sometimes it depends on the selection scheme used (for example, in tournament selection where the $T$ parameter, along with the population size determines the mating pool size).\n",
    "\n",
    "For simplicity in this demo, let's fix the number of parents that are selected to mate at every iteration and store it as a variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MATING = 0 # Fill in a number of your choice > 0 \n",
    "\n",
    "def select_determinstic(t_pop, t_fitness):\n",
    "    \"\"\" Given current population t_pop, select N_MATING number of parents using determinstic selection scheme\n",
    "    based on t_fitness (the fitness of the population) \n",
    "\n",
    "    Returns parents and their fitness as a tuple (parent, fitness_of_parents)\n",
    "    \"\"\"\n",
    "    # Fill in details here \n",
    "    parents = np.empty((N_MATING, N_WEIGHTS))\n",
    "    \n",
    "    return (parents, calc_fitness(parents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "my_parents, my_par_fitness = select_determinstic(curr_population, my_fitness)\n",
    "my_parents\n",
    "my_par_fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you show me an example of stochastic selection?\n",
    "\n",
    "Let's implement Stochastic Universal Sampling, which consists of\n",
    "\n",
    "* Sampling rate assignment\n",
    "* Sampling\n",
    "\n",
    "I will demonstrate this in class as its a bit more involved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variation\n",
    "Variation has two operations : crossover/recombination (produce new offspring from the parents selected in the prior step) and mutation (produced mutated/randomly offset offspring). Let's see each one separately.\n",
    "\n",
    "### Recombination\n",
    "For this demonstration, lets do a one-point crossover. This means we naively *mix* the solution vectors---we take some  components from one parent and the rest from another parent... \n",
    "\n",
    "Before proceeding, we want to determine the limit of offspring vectors to be produced. This has to be a reasonable number and should depend on the population and the number of parents selected for mating. This also corresponds to the $\\lambda$ deterministic selection schemes.\n",
    "\n",
    "We also need to select $p_c$, the crossover rate---it determines the probability of a crossover happening between two parents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our demo, let's fix $p_c$ to 1 (recombination happens always). We also fixed the offspring size above to $0.5 \\cdot {\\text{N-MATING}\\choose 2} = 3$. This allows every selected parent to propogate their genes. The parent vectors are chosen in a fixed fashion (1 mates with 2, 2 with 3 and so on...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where to crossover? Sometimes we use an additional random integer (respecting array range constraints) that determines at which location a crossover should occur. In our example below, let's perform a *uniform* one-point crossover (uniform in the sense that we always do crossover at a selected index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OFFSPRING =  0 # Fill in how many offspring you want\n",
    "IDX_CROSSOVER = 9999 # Fill in at which index you want crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(t_parents):\n",
    "    \"\"\" Given a set of parents, combine them and return offspring vectors\n",
    "    \n",
    "    Returns the offsprings and their fitness\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create an emppty vector\n",
    "    offspring = np.empty((N_OFFSPRING, N_WEIGHTS))\n",
    "\n",
    "    # Fill in crossover details\n",
    "    \n",
    "    return (offspring, calc_fitness(offspring))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does crossover create new offspring?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "my_offspring,  my_offspring_fitness = crossover(my_parents)\n",
    "my_parents\n",
    "my_offspring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does! Are the offsprings fitter than their parents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if recombination is useful\n",
    "my_par_fitness\n",
    "my_offspring_fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are! This is good news..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutation\n",
    "For this demonstration, lets add uniform random numbers drawn between $[-0.5, 0.5)$ to the offspring. But let's not do it everytime---we will do that with a probability $p_m = 0.5$, sampled for each offspring. Recollect that this is the mutation rate parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM = 1000000 # Mutation rate parameter\n",
    "def mutation(t_offspring):\n",
    "    \"\"\" Given a set of offsprings, introduce mutation in them\n",
    "   \n",
    "    Returns the mutated offsprings and their fitness\n",
    "    \"\"\"\n",
    "    # Fill in details\n",
    "    mutated_offspring = np.empty(t_offspring.shape)\n",
    "    \n",
    "    return (mutated_offspring, calc_fitness(mutated_offspring))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we see some mutation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "my_mut_offspring, my_mut_offspring_fitness = mutation(my_offspring)\n",
    "my_offspring\n",
    "my_mut_offspring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environmental selection\n",
    "The final step is environmental selection. This comes in two parts:\n",
    "\n",
    "1) Imposing any hard constraints, such as those violating range being chucked out\n",
    "\n",
    "2) Picking the `POP_SIZE` best individuals and sending them to the next generation\n",
    "\n",
    "\n",
    "\n",
    "Let's first throw out any individuals not adhering to the limits set by or constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_constraint(t_total_pop):\n",
    "    \"\"\" Scans the array for individual violating constraint bounds\n",
    "    and chucks them out of processing\n",
    "\n",
    "    t_total_pop includes all vectors (parents + mutated offsprings)\n",
    "    (this is done for you below, so don't worry about it)\n",
    "    \"\"\"\n",
    "    # Fill in details on how you eject solutions not in decision space\n",
    "    # or search space\n",
    "    modified_pop = t_total_pop.copy()\n",
    "    \n",
    "    return modified_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the constraint check passes. Let's concatenate all vectors into one big unit and do constraint check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing constraints \n",
    "# Group curr_population, my_parents, my_mut_offspring here\n",
    "# Stack them one top of another\n",
    "total_population = np.vstack((curr_population, my_mut_offspring))\n",
    "\n",
    "# Verify shape\n",
    "total_population.shape\n",
    "\n",
    "total_population = hard_constraint(total_population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then pick the top `POP_SIZE` individuals next, based on their fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def environmental_selection(t_total_pop):\n",
    "    \"\"\" Calculate total population (after constraint checking) fitness,\n",
    "    rank accoridingly and select only the top POP_SIZE individuals to\n",
    "    pass on to the next generation\n",
    "    \"\"\" \n",
    "\n",
    "    # Fill in details\n",
    "    \n",
    "    return t_total_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether selecting top 10 works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before\")\n",
    "total_population.shape\n",
    "calc_fitness(total_population)\n",
    "new_population = environmental_selection(total_population)\n",
    "print(\"After\")\n",
    "new_population.shape\n",
    "calc_fitness(new_population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's hook them all up together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And add some utilities to help us track progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_outputs = []\n",
    "num_generations = 1000\n",
    "curr_population = rng.uniform(low=-4.0, high=4.0, size=DOFS_IN_POP)\n",
    "overall_max_fitness = -99999\n",
    "\n",
    "# Run many iterations\n",
    "# You should also have another convergence check\n",
    "for generation in range(num_generations):\n",
    "    print(\"Generation : \", generation)\n",
    "\n",
    "    # Measuring the fitness of each chromosome in the population.\n",
    "    fitness = calc_fitness(curr_population)\n",
    "\n",
    "    # print(\"Fitness\")\n",
    "    # print(fitness)\n",
    "\n",
    "    max_fitness = np.max(fitness)\n",
    "\n",
    "    # The best result in the current iteration.\n",
    "    print(\"Best result in current iteration {0} compared to overall {1}\".format(max_fitness, max(max_fitness, overall_max_fitness)))\n",
    "    best_outputs.append(max_fitness)\n",
    "    \n",
    "    # Selecting the best parents in the population for mating.\n",
    "    parents, _ = select_determinstic(curr_population, fitness)\n",
    "#     parents, _ = select_stochastic(curr_population, fitness)\n",
    "    \n",
    "    # print(\"Parents\")\n",
    "    # print(parents)\n",
    "\n",
    "    # Generating next generation using crossover.\n",
    "    offspring_crossed, _ = crossover(parents)\n",
    "\n",
    "    # print(\"Crossover\")\n",
    "    # print(offspring_crossover)\n",
    "\n",
    "    # Adding some variations to the offspring using mutation.\n",
    "    offspring_mutated, _ = mutation(offspring_crossed)\n",
    "\n",
    "    # print(\"Mutation\")\n",
    "    # print(offspring_mutation)\n",
    "\n",
    "    # Check for constraints\n",
    "    total_population = np.vstack((curr_population, offspring_mutated))\n",
    "    total_population = hard_constraint(total_population)\n",
    "\n",
    "    # Environmental selection\n",
    "    curr_population = environmental_selection(total_population)\n",
    "              \n",
    "# Getting the best solution after iterating finishing all generations.\n",
    "#At first, the fitness is calculated for each solution in the final generation.\n",
    "fitness = calc_fitness(curr_population)\n",
    "\n",
    "# Then return the index of that solution corresponding to the best fitness.\n",
    "max_idx = np.argmax(fitness)\n",
    "\n",
    "print(\"Best solution : \", new_population[max_idx, :])\n",
    "print(\"Best solution fitness : \", fitness[max_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our GA performed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(best_outputs,'-o', lw=3, ms=20, label='from scratch')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(120-np.array(best_outputs),'-o', lw=3, ms=20, label='from scratch')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yay! Looks like it works, although not very well. Explore and see what can be improved\n",
    "\n",
    "Acknowledgement: Content from this notebook is drawn from Ahmed Gad's GA implementation, found at his [Github](https://github.com/ahmedfgad/GeneticAlgorithmPython)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are not done yet!\n",
    "\n",
    "To have a black box optimizer, we need to wrap all this functionality into something that's abstracted away from the end user (in this case you). What does that mean? Think about:\n",
    "- Change in the cost function (Knapsack, Rastrigin)\n",
    "    - Function changes (and along with it discontinuities, ill-conditioning, non-separability...)\n",
    "    - Dimensionality of the problem changes (n=1,...,100,...1000?)\n",
    "    - Other concerns\n",
    "- Change in the encoding (reals, bitvectors)\n",
    "- ...\n",
    "\n",
    "That is to say, write something well once and keep on reusing it---functions! Also store associated variables---classes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW : Wrap this up in a GA class and reuse it in your applications (Project 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(my_func):\n",
    "    return my_func(2.0)\n",
    "    \n",
    "fitness(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
